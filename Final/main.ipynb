{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final TP\n",
    "\n",
    "- XGBoost and AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import scipy\n",
    "import mne\n",
    "\n",
    "from collections import Counter\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mne.datasets.sleep_physionet.age import fetch_data\n",
    "\n",
    "import epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "psg_data\n",
    "    The psg_data variable contains polysomnography data, which typically includes multiple physiological signals such as EEG, EOG, and EMG, recorded during sleep.\n",
    "\n",
    "hypnogram_data\n",
    "    The hypnogram_data variable represents annotations or labels associated with sleep stages, providing information about the temporal distribution of wakefulness, different sleep stages (NREM and REM), and transitions during a sleep recording.\n",
    "    \n",
    "fs \n",
    "    represents the sampling frequency (or sampling rate) of the polysomnography (PSG) data, indicating the number of samples per second in the signal.\n",
    "\"\"\"\n",
    "\n",
    "# Reading data (psg) and hypnogram (labels)\n",
    "psg_file = \"data/SC4001E0-PSG.edf\"\n",
    "hypnogram_file = \"data/SC4001EC-Hypnogram.edf\"\n",
    "\n",
    "# psg_data = mne.io.read_raw_edf(psg_file)\n",
    "# hypnogram_data = mne.read_annotations(hypnogram_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /Users/stig/Desktop/- TU:e/5Q1 ITBA Buenos Aires/72.75 Aprendizarje Automatico/72.75-ML/final/data/SC4001E0-PSG.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stig/Desktop/- TU:e/5Q1 ITBA Buenos Aires/72.75 Aprendizarje Automatico/72.75-ML/final/epoch.py:117: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  psg_data_raw.set_annotations(hypnogramm_annotations)\n"
     ]
    }
   ],
   "source": [
    "s = epoch.sleepRecording()\n",
    "s.init_from_file(\"data/SC4001E0-PSG.edf\", \"data/SC4001EC-Hypnogram.edf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleep stage W: 1997\n",
      "Sleep stage 1: 58\n",
      "Sleep stage 2: 250\n",
      "Sleep stage 3: 101\n",
      "Sleep stage 4: 119\n",
      "Sleep stage R: 125\n"
     ]
    }
   ],
   "source": [
    "# Checking how much of each label we have in the dataset\n",
    "\n",
    "label_list = [s.epochs[i].label for i in range(len(s.epochs))]\n",
    "label_counts = Counter(label_list)\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"{label}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EEG Fpz-Cz',\n",
       " 'EEG Pz-Oz',\n",
       " 'EOG horizontal',\n",
       " 'Resp oro-nasal',\n",
       " 'EMG submental',\n",
       " 'Temp rectal',\n",
       " 'Event marker']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.epochs[10].ch_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from createFeatures import create_features_recording_session\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2120, 15)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FREQ_BANDS = {'SO':[0.5, 1],\n",
    "            'delta': [1, 4],\n",
    "            'theta': [4, 8],\n",
    "            'alpha': [8, 13],\n",
    "            'sigma': [13,15],\n",
    "            'beta': [15, 30],\n",
    "            'gamma': [30, 60]}\n",
    "\n",
    "# Applying feature extraction functions to each epoch\n",
    "create_features_recording_session(s)\n",
    "\n",
    "# Initialize lists for features and labels\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Iterate over each epoch to gather features and labels\n",
    "for e in s.epochs:\n",
    "    # Extract the features for the current epoch\n",
    "    feature_row = [e.features[f'integral_{band}_Pz-Oz'] for band in FREQ_BANDS] + \\\n",
    "                  [e.features[f'integral_{band}_Fpz-Cz'] for band in FREQ_BANDS] + \\\n",
    "                  [e.features['avg_temp']]\n",
    "    \n",
    "    # Append the feature row and label to their respective lists\n",
    "    features.append(feature_row)\n",
    "    labels.append(e.label)\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X = np.array(features)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Handling missing values (if any)\n",
    "# Example: Replace NaNs with the mean of the respective column\n",
    "X = np.nan_to_num(X, nan=np.nanmean(X))\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Splitting the dataset into Training and Test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.96044414e-01, -4.36557503e-01, -8.31992680e-01, ...,\n",
       "        -8.17114069e-01, -8.67001411e-01,  2.30210468e-01],\n",
       "       [-2.55430189e-01, -2.81306440e-01, -1.97783460e-04, ...,\n",
       "        -1.21320996e+00, -1.22514941e+00, -7.84179473e-01],\n",
       "       [-4.00882658e-01, -4.43575610e-01, -4.72969343e-01, ...,\n",
       "         3.52760626e-01, -1.00102220e-01,  1.93839639e-01],\n",
       "       ...,\n",
       "       [ 1.37173374e+00,  3.78380443e+00,  1.78247445e+00, ...,\n",
       "        -1.27319533e+00, -1.25689200e+00, -1.28593421e+00],\n",
       "       [ 1.31136347e-01,  3.19079436e-01,  4.09858494e-01, ...,\n",
       "        -1.24564139e+00, -1.25491878e+00, -1.54588001e+00],\n",
       "       [-4.76500996e-02, -3.37125288e-01, -1.97046517e-01, ...,\n",
       "         5.37801623e-01,  9.08775773e-01, -3.14097082e-01]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
